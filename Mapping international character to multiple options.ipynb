{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This notebook tries to resolve the stackoverflow http://stackoverflow.com/questions/42301375/mapping-international-character-to-multiple-options question with an adhoc example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we need a custom translation. By now I've only set those chars that you shown, but feel free to complete the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accented_letters = {\n",
    "    u'ö' : [u'o',u'oe'],\n",
    "    u'ø' : [u'o',u'oe'],\n",
    "}\n",
    "\n",
    "def normalize_word(word):\n",
    "    _word = word\n",
    "    for c in word:\n",
    "        for replacement in accented_letters.get(c,[]):\n",
    "            _word = word.replace(c,replacement)\n",
    "    return _word\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can normalize words and store them in a special property, `body_normalized` for instance, and index them as a field of your Elasticsearch records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body Paul Jorgensen, South African Advocate\n",
      "body_normalized paul jorgensen south african advocate\n",
      "body Andy Jörgensen, American politician, Wisconsin State Assembly\n",
      "body_normalized andy joergensen american politician wisconsin state assembly\n",
      "body Anker Jørgensen, Danish Prime Minister\n",
      "body_normalized anker joergensen danish prime minister\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "texts = [\n",
    "    u\"Paul Jorgensen, South African Advocate\",\n",
    "    u\"Andy Jörgensen, American politician, Wisconsin State Assembly\",\n",
    "    u\"Anker Jørgensen, Danish Prime Minister\",\n",
    "]\n",
    "records = []\n",
    "\n",
    "for text in texts:\n",
    "    text_parts = [p.strip() for p in re.split('[,\\s]',text)]\n",
    "    text_normalized = []\n",
    "    for tp in text_parts:\n",
    "        tp = tp.strip().lower()\n",
    "        if tp:\n",
    "            text_normalized.append(normalize_word(tp)) \n",
    "                \n",
    "    record = {\n",
    "        'body' : text,\n",
    "    }\n",
    "    if text_normalized:\n",
    "        record['body_normalized'] = ' '.join(text_normalized)\n",
    "    records.append(record)\n",
    "\n",
    "for r in records:\n",
    "    for k,v in r.iteritems():\n",
    "        print k,v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "#cluster node to query\n",
    "es = Elasticsearch(['localhost:9200',])\n",
    "index_name    = 'your_index'\n",
    "\n",
    "\n",
    "\n",
    "es.indices.create(\n",
    "    index = index_name,\n",
    ")\n",
    "\n",
    "kwargs = {\n",
    "    'body' : []\n",
    "}\n",
    "\n",
    "index_config = { \n",
    "    \"_type\"  : \"your_type\", \n",
    "    \"_index\" : 'your_index', \n",
    "}\n",
    "for idx,r in enumerate(records):\n",
    "    _index_config = dict(index_config)\n",
    "    _index_config['_id'] = idx\n",
    "    kwargs['body'].append({'index' : _index_config})\n",
    "    kwargs['body'].append(r)\n",
    "\n",
    "_ = es.bulk(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once they are inserted, you could perform two types of search:<br>\n",
    "    1. exact search: User input isn't normalized and Elasticsearch query search against `body` field, that isn't normalized too.\n",
    "    2. simliar search. User input is normalized and we'll search againts `body_normalized` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------EXACT MATCH------\n",
      "Jorgensen  MATCHING BODIES= 1\n",
      "- Paul Jorgensen, South African Advocate\n",
      "Jörgensen  MATCHING BODIES= 1\n",
      "- Andy Jörgensen, American politician, Wisconsin State Assembly\n",
      "Jørgensen  MATCHING BODIES= 1\n",
      "- Anker Jørgensen, Danish Prime Minister\n",
      "Joergensen  MATCHING BODIES= 0\n",
      "\n",
      "------SIMILAR MATCHES------\n",
      "Jorgensen  MATCHING NORMALIZED BODIES= 3\n",
      "- Paul Jorgensen, South African Advocate\n",
      "- Anker Jørgensen, Danish Prime Minister\n",
      "- Andy Jörgensen, American politician, Wisconsin State Assembly\n",
      "Joergensen  MATCHING NORMALIZED BODIES= 2\n",
      "- Anker Jørgensen, Danish Prime Minister\n",
      "- Andy Jörgensen, American politician, Wisconsin State Assembly\n",
      "Joergensen  MATCHING NORMALIZED BODIES= 2\n",
      "- Anker Jørgensen, Danish Prime Minister\n",
      "- Andy Jörgensen, American politician, Wisconsin State Assembly\n",
      "Joergensen  MATCHING NORMALIZED BODIES= 2\n",
      "- Anker Jørgensen, Danish Prime Minister\n",
      "- Andy Jörgensen, American politician, Wisconsin State Assembly\n"
     ]
    }
   ],
   "source": [
    "\n",
    "body_matches = [\n",
    "    u'Jorgensen',\n",
    "    u'Jörgensen',\n",
    "    u'Jørgensen',\n",
    "    u'Joergensen',\n",
    "]\n",
    "print \"------EXACT MATCH------\"\n",
    "for body_match in body_matches:\n",
    "    elasticsearch_query = {\n",
    "        \"query\": {\n",
    "            \"match\" : {\n",
    "                \"body\" : body_match\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es_kwargs = { \n",
    "        \"doc_type\"  : \"your_type\", \n",
    "        \"index\" : 'your_index', \n",
    "        \"body\" : elasticsearch_query\n",
    "    }\n",
    "\n",
    "    res = es.search(**es_kwargs)\n",
    "    print body_match,\" MATCHING BODIES=\",res['hits']['total']\n",
    "\n",
    "    for r in res['hits']['hits']:\n",
    "        print \"-\",r['_source'].get('body','')\n",
    "\n",
    "print \"\\n------SIMILAR MATCHES------\"\n",
    "for body_match in body_matches:\n",
    "    body_match = normalize_word(body_match)\n",
    "    elasticsearch_query = {\n",
    "        \"query\": {\n",
    "            \"match\" : {\n",
    "                \"body_normalized\" : body_match\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es_kwargs = { \n",
    "        \"doc_type\"  : \"your_type\", \n",
    "        \"index\" : 'your_index', \n",
    "        \"body\" : elasticsearch_query\n",
    "    }\n",
    "\n",
    "    res = es.search(**es_kwargs)\n",
    "    print body_match,\" MATCHING NORMALIZED BODIES=\",res['hits']['total']\n",
    "\n",
    "    for r in res['hits']['hits']:\n",
    "        print \"-\",r['_source'].get('body','')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
